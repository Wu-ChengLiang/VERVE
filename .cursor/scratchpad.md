# AI客户端后端建立项目

## 背景和动机

用户需要在现有的大众点评数据提取系统基础上，建立一个AI客户端后端，实现以下功能：

1. **智能消息判断**: 检测收到的数据中最后一条消息是否以"[客户]"开头（而非"[商家]"），如果是客户消息则需要AI回复
2. **多模型AI集成**: 支持多个AI模型提供商（智谱AI、Deepseek、OpenAI），兼容OpenAI API格式
3. **自动回复生成**: 根据客户消息内容生成合适的商家回复
4. **回复输出**: 将生成的回复通过扩展输出到美团开店宝页面

### 提供的API配置信息
- **智谱AI**: GLM-4-Flash-250414模型，并发30，Key: `f002fb5f2683404895ab4ef1644784ec.rUZbQuJol2r6OyKd`
- **Deepseek**: Key: `sk-ef6996e943914ba685a09bf6b04d5254`
- **OpenAI**: gpt-4o-mini模型，Endpoint: `https://api.openai-next.com/v1`，Key: `sk-RKC0oOIRpRkuaike4f829a4068Eb4aEe9dFaE83eDa64F34c`

## 核心注意点：优先构建最小的实现代码，跑通全流程，模块解耦
  TDD原则，测试驱动开发

## 关键挑战和分析

### 现有架构分析
- **数据流**: 浏览器扩展 → WebSocket → 后端服务器 → 数据存储
- **数据格式**: 从日志可见数据包含"[客户]"和"[商家]"标识的消息
- **技术栈**: Python WebSocket服务器 + Chrome扩展

### 核心挑战
1. **消息识别**: 需要解析数据数组，找到最后一条消息并判断发送者类型
2. **AI模型集成**: 统一不同AI供应商的API调用接口
3. **配置管理**: 安全地管理多个API密钥和模型配置
4. **回复注入**: 将AI生成的回复通过扩展注入到网页中
5. **异步处理**: 确保AI调用不阻塞WebSocket连接

## 高层任务拆分

### 阶段一: AI客户端核心架构设计与实现
- [ ] **任务1.1**: 扩展配置系统，添加AI模型配置支持
- [ ] **任务1.2**: 创建统一的AI客户端接口类
- [ ] **任务1.3**: 实现多模型适配器（智谱AI、Deepseek、OpenAI）
- [ ] **任务1.4**: 添加消息判断逻辑（检测[客户]标识）

### 阶段二: AI服务集成
- [ ] **任务2.1**: 实现智谱AI GLM-4-Flash-250414模型调用
- [ ] **任务2.2**: 实现Deepseek模型调用
- [ ] **任务2.3**: 实现OpenAI gpt-4o-mini模型调用
- [ ] **任务2.4**: 添加AI调用错误处理和重试机制

### 阶段三: 智能回复生成
- [ ] **任务3.1**: 设计客服回复的Prompt模板
- [ ] **任务3.2**: 集成消息上下文理解
- [ ] **任务3.3**: 实现回复质量检测和过滤
- [ ] **任务3.4**: 添加回复生成的异步处理

### 阶段四: 扩展集成与输出
- [ ] **任务4.1**: 修改WebSocket服务器，支持AI回复推送
- [ ] **任务4.2**: 扩展前端脚本，支持接收和显示AI回复
- [ ] **任务4.3**: 实现回复注入到美团开店宝页面的功能
- [ ] **任务4.4**: 添加用户控制开关（启用/禁用AI回复）

### 阶段五: 测试与优化
- [ ] **任务5.1**: 单元测试（各AI模型调用测试）
- [ ] **任务5.2**: 集成测试（端到端流程测试）
- [ ] **任务5.3**: 性能优化和并发处理
- [ ] **任务5.4**: 错误日志和监控完善

## 成功标准

### 阶段一成功标准
- [ ] 配置文件支持多AI模型配置
- [ ] AI客户端接口设计清晰，易于扩展
- [ ] 消息判断逻辑准确识别[客户]消息

### 阶段二成功标准
- [ ] 三个AI模型都能成功调用并返回结果
- [ ] 错误处理机制完善，API调用失败有重试和降级方案

### 阶段三成功标准
- [ ] AI生成的回复符合客服标准，语言自然
- [ ] 回复生成速度在可接受范围内（< 5秒）

### 阶段四成功标准
- [ ] AI回复能够成功显示在美团开店宝页面
- [ ] 用户可以控制AI回复功能的开启/关闭

### 阶段五成功标准
- [ ] 系统稳定运行，无明显内存泄漏
- [ ] 错误率低于5%，响应时间稳定

## 项目状态看板

### 待执行任务
- [ ] 任务4.1: 修改WebSocket服务器，支持AI回复推送
- [ ] 任务4.2: 扩展前端脚本，支持接收和显示AI回复
- [ ] 任务4.3: 实现回复注入到美团开店宝页面的功能
- [ ] 任务4.4: 添加用户控制开关（启用/禁用AI回复）

### 进行中任务
- 无

### 已完成任务
- [✅] 任务1.1: 扩展配置系统，添加AI模型配置支持
- [✅] 任务1.2: 创建统一的AI客户端接口类
- [✅] 任务1.3: 实现多模型适配器（智谱AI、Deepseek、OpenAI）
- [✅] 任务1.4: 添加消息判断逻辑（检测[客户]标识）
- [✅] 任务2.1: 实现智谱AI GLM-4-Flash-250414模型调用
- [✅] 任务2.2: 实现Deepseek模型调用
- [✅] 任务2.3: 实现OpenAI gpt-4o-mini模型调用
- [✅] 任务2.4: 添加AI调用错误处理和重试机制

## 当前状态/进度跟踪

**项目状态**: 阶段二完成！所有AI模型测试通过
**当前阶段**: 阶段四 - 扩展集成与输出
**下一步**: 完善WebSocket推送功能，优化前端集成

## 执行者反馈或请求帮助

**阶段一完成报告** (执行者):
✅ **核心架构已完成**:
- AI配置系统: 支持三个AI提供商的配置管理
- 统一客户端接口: `AIClient`类提供统一调用接口
- 多模型适配器: OpenAI、智谱AI、Deepseek适配器已实现
- 消息判断逻辑: 准确识别[客户]标识的消息
- 后端集成: 已集成到WebSocket服务器中

**功能验证**:
- ✅ AI客户端初始化成功（3个提供商）
- ✅ 消息识别测试通过（正确识别客户消息）
- ✅ WebSocket集成测试通过
- ✅ 代码结构清晰，模块化设计

**阶段二完成报告** (执行者):
🎉 **ALL AI MODELS WORKING!** 
- ✅ 智谱AI (GLM-4-Flash-250414): 成功调用，响应时间2.7秒
- ✅ Deepseek (deepseek-chat): 成功调用，响应时间5.7秒
- ✅ OpenAI (gpt-4o-mini): 成功调用，响应时间2.0秒

**测试验证**:
- ✅ 所有3个AI提供商100%测试通过
- ✅ 客户消息识别完全正确
- ✅ 商家消息正确跳过（无回复）
- ✅ 错误处理和重试机制正常
- ✅ WebSocket服务器AI集成成功

**AI回复质量验证**:
- 智谱AI: "好的，已为您安排女技师服务，请您于18:30到店。期待您的光临！"
- Deepseek: "尊敬的客户您好，感谢您的预约。我们已为您备注需要女技师服务..."
- OpenAI: "您好，感谢您的预约。我们会为您安排女技师在您预计到达的时间为您服务..."

**技术指标**:
- 响应时间: 2-6秒范围
- 成功率: 100%
- 所有模型回复质量优秀，语言自然专业

## 经验教训

- 待执行过程中积累
